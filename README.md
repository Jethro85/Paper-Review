# Paper-Review
This repo contains notes and short summaries of some DNN security related papers I come across.

## Backdoor Attack

- [x] Latent Backdoor Attacks on Deep Neural Networks (CCS 2019): [[Paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/pbackdoor-ccs19.pdf)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Latent%20Backdoor%20Attacks%20on%20Deep%20Neural%20Networks.md)]

## Backdoor Detection and Mitigation
- [x] Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks (S&P 2019): [[Paper](https://sites.cs.ucsb.edu/~bolunwang/assets/docs/backdoor-sp19.pdf)] [[Code](https://github.com/bolunwang/backdoor)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Neural%20Cleanse-%20Identifying%20and%20Mitigating%20Backdoor%20Attacks%20in%20Neural%20Networks.md)]

- [x] STRIP: A Defence Against Trojan Attacks on Deep Neural Networks (2019 ACSAC): 
[[Paper](https://arxiv.org/pdf/1902.06531.pdf)] [[Code](https://github.com/garrisongys/STRIP)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/STRIP-%20A%20Defence%20Against%20Trojan%20Attacks%20on%20Deep%20Neural%20Networks.md)]

- [x] Design and Evaluation of a Multi-Domain Trojan Detection Method on Deep Neural Networks (2019): [[Paper](https://arxiv.org/pdf/1911.10312.pdf)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Design%20and%20Evaluation%20of%20a%20Multi-Domain%20Trojan%20Detection%20Method%20on%20Deep%20Neural%20Networks.md)]

- [x] DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks (IJCAI 2019):
[[Paper](https://cseweb.ucsd.edu/~jzhao/files/DeepInspect-IJCAI2019.pdf)] [[Notes]()] [[Citation](https://dblp.uni-trier.de/rec/bibtex/conf/ijcai/ChenFZK19)]

- [ ] ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation (CCS 2019): [[Paper](https://www.cs.purdue.edu/homes/taog/docs/CCS19.pdf)]

- [x] TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems (2019): 
[[Paper](https://arxiv.org/pdf/1908.01763.pdf)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/TABOR-%20A%20Highly%20Accurate%20Approach%20to%20Inspecting%20and%20Restoring%20Trojan%20Backdoors%20in%20AI%20Systems.md)]

- [x] Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering (2019 AAAI): [[Paper](https://arxiv.org/pdf/1811.03728.pdf)] [[Code](https://github.com/IBM/adversarial-robustness-toolbox/blob/master/examples/mnist_poison_detection.py)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Detecting%20Backdoor%20Attacks%20on%20Deep%20Neural%20Networks%20by%20Activation%20Clustering.md)] [[Citation](https://dblp.uni-trier.de/rec/bibtex/conf/aaai/ChenCBLELMS19)]





## Watermarking
- [x] Leveraging Unlabeled Data for Watermark Removal of Deep Neural Networks (ICML 2019): [[Paper](https://ruoxijia.github.io/assets/papers/watermark_removal_icml19_workshop.pdf)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Leveraging%20Unlabeled%20Data%20for%20Watermark%20Removal%20of%20Deep%20Neural%20Networks.md)]

- [x] Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring (usenix 2018): [[Paper](https://arxiv.org/pdf/1802.04633.pdf)] [[Code](https://github.com/adiyoss/WatermarkNN)] [[Blog]( https://medium.com/@carstenbaum/the-ubiquity-of-machine-learning-and-its-challenges-to-intellectual-property-dc38e7d66b05)] [[Notes](https://github.com/Jethro85/Paper-Review/blob/master/Turning%20Your%20Weakness%20Into%20a%20Strength-%20Watermarking%20Deep%20Neural%20Networks%20by%20Backdooring.md)]

